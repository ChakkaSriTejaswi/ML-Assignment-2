{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "B5RHiAX0XXX9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef\n",
    ")\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UFse_y_XzWR",
    "outputId": "6c7843e7-0356-4b45-9943-382ba6948bfc"
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "columns = [\"ID\", \"Diagnosis\"] + [f\"feature_{i}\" for i in range(1, 31)]\n",
    "df = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Convert target to numeric (M=1, B=0)\n",
    "df['Diagnosis'] = df['Diagnosis'].map({'M': 1, 'B': 0})\n",
    "df = df.drop(\"ID\", axis=1)\n",
    "\n",
    "X = df.drop(\"Diagnosis\", axis=1)\n",
    "y = df[\"Diagnosis\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split on scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "s7saHo7eYtEq"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=2000, solver=\"lbfgs\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arMDmVEvY0jY",
    "outputId": "19fe884c-da3c-4564-a5e4-85228f208047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy       AUC  Precision    Recall        F1  \\\n",
      "0  Logistic Regression  0.973684  0.997380   0.976190  0.953488  0.964706   \n",
      "1        Decision Tree  0.938596  0.936947   0.909091  0.930233  0.919540   \n",
      "2                  KNN  0.947368  0.981657   0.930233  0.930233  0.930233   \n",
      "3          Naive Bayes  0.964912  0.997380   0.975610  0.930233  0.952381   \n",
      "4        Random Forest  0.964912  0.994104   0.975610  0.930233  0.952381   \n",
      "5              XGBoost  0.956140  0.990829   0.952381  0.930233  0.941176   \n",
      "\n",
      "        MCC  \n",
      "0  0.943898  \n",
      "1  0.870056  \n",
      "2  0.887979  \n",
      "3  0.925285  \n",
      "4  0.925285  \n",
      "5  0.906379  \n"
     ]
    }
   ],
   "source": [
    "# Create project folder and model subfolder\n",
    "os.makedirs(\"project-folder\", exist_ok=True)\n",
    "os.makedirs(\"project-folder/model\", exist_ok=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    metrics = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_prob) if y_prob is not None else None,\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
    "    }\n",
    "    results.append(metrics)\n",
    "    \n",
    "    # Save trained model\n",
    "    joblib.dump(model, f\"project-folder/model/{name.replace(' ', '_')}.pkl\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
